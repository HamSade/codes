#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Mon Mar 20 10:46:41 2017

@author: hsadeghi
"""

from __future__ import division, print_function, absolute_import

import tensorflow as tf

import numpy as np
#import matplotlib.pyplot as plt
import scipy.io as si #for reading the data


#%%
#loading data

mat = si.loadmat('/home/hsadeghi/Downloads/PDA/my_data/com_concat_signal.mat')   ;
fs=np.asscalar(mat['fs_new']);

data=mat['concat_wav'];  # 100 files of 5 summed speakers, each file a few secs
data=np.array(data); 
#data.shape: (1, 15603279)
# >> median(abs(concat_wav)) = 0.0376

n_data=data.shape[1];
#input_dim =int(fs/25); # Frames size of speech signal
input_dim =100;

n_data=n_data - n_data % input_dim; # make length divisible by input_dim
data=data[0,0:n_data]; # clipping teh rest
# Reshaping data
data=data.reshape([int(n_data/input_dim), input_dim])
n_data=data.shape[0];

#data=tf.cast(data, tf.float32)


training_percentage=90;
n_training= int(np.floor(training_percentage/100.*n_data));
training_data=data[ 0:n_training , : ];

test_data=data[ n_training:n_data, : ];
n_test=test_data.shape[0];



#%% Parameters

learning_rate = 0.001
training_iters = 1000
num_steps = 2 # timesteps
display_step = 100
training_epochs=1;

batch_size = 128
num_batches= 2000; # int(n_training/batch_size)


# Network Parameters
input_dim = 128


full_width=512; # number of neurons in the fully connected par

rnn_width = 512 # number of neurons in the rnn part
num_layers=2

num_binary=16;


#%% tf Graph input
X = tf.placeholder('float', [None, input_dim])

# define states??!! Not sure if required or not!
previous_state_enc=tf.placeholder('float', [rnn_width, num_layers])
previous_state_dec=tf.placeholder('float', [rnn_width, num_layers])

std_init_W=0.1;
std_init_bias=0.01;

weights={};
biases={};

# Fully connected
weights['encoder_full']= tf.Variable(tf.random_normal([input_dim, full_width], mean=0.0, stddev=std_init_W));                                
biases['encoder_full']= tf.Variable(tf.random_normal([full_width],  mean=0.0, stddev=std_init_bias));

#rnn
weights['encoder_rnn_1' ]= tf.Variable(tf.random_normal( [full_width, rnn_width], mean=0.0, stddev=std_init_W));
biases ['encoder_rnn_1' ]= tf.Variable(tf.random_normal( [rnn_width],  mean=0.0, stddev=std_init_bias));

weights['encoder_rnn_2' ]= tf.Variable(tf.random_normal( [rnn_width, rnn_width], mean=0.0, stddev=std_init_W));
biases ['encoder_rnn_2' ]= tf.Variable(tf.random_normal( [rnn_width],  mean=0.0, stddev=std_init_bias));

# Fully connected
weights['middle']=tf.Variable(tf.random_normal( [rnn_width, num_binary], mean=0.0, stddev=std_init_W));
biases['middle']= tf.Variable(tf.random_normal( [num_binary],  mean=0.0, stddev=std_init_bias));

#rnn
weights['decoder_rnn_1']= tf.Variable(tf.random_normal( [num_binary, rnn_width], mean=0.0, stddev=std_init_W));
biases ['decoder_rnn_1']= tf.Variable(tf.random_normal( [rnn_width],  mean=0.0, stddev=std_init_bias));

weights['decoder_rnn_2']= tf.Variable(tf.random_normal( [rnn_width, rnn_width], mean=0.0, stddev=std_init_W));
biases ['decoder_rnn_2']= tf.Variable(tf.random_normal( [rnn_width],  mean=0.0, stddev=std_init_bias));

# Fully connected
weights['decoder_full']=tf.Variable(tf.random_normal( [rnn_width, full_width], mean=0.0, stddev=std_init_W));
biases['decoder_full']= tf.Variable(tf.random_normal( [full_width],  mean=0.0, stddev=std_init_bias));

# Fully connected
weights['output']= tf.Variable(tf.random_normal([full_width, input_dim], mean=0.0, stddev=std_init_W));
biases['output']=tf.Variable(tf.random_normal([input_dim], mean=0.0, stddev=std_init_bias));


#%%
# Batch normalization


def BatchNormalization(x, w):
    epsilon=1e-3;
    
    num_neurons=w.get_shape()[1].value;
    
    
    x=tf.cast(x, tf.float32)
    w=tf.cast(w, tf.float32)
    
    z_BN = tf.matmul(x,w)

    batch_mean, batch_var = tf.nn.moments(z_BN,[0])
    scale = tf.Variable(tf.ones([num_neurons]))
    beta = tf.Variable(tf.zeros([num_neurons]))
    x_BN = tf.nn.batch_normalization(z_BN,batch_mean,batch_var,beta,scale,epsilon)

    return x_BN


#%% RNN layer definition

def rnn_layer_gen(rnn_width): #, w, b):

    # Prepare data shape to match `rnn` function requirements    
    # Current data input shape: (batch_size, n_steps, input_dim)-->Have to feed in data in this form
    #*****    
    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)

    # Permuting batch_size and n_steps
#    x = tf.transpose(x, [1, 0, 2])
#    # Reshaping to (n_steps*batch_size, n_input)
#    x = tf.reshape(x, [-1, input_dim])
#    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)
#    x = tf.split(x, num_steps, 0)

    # Define a lstm cell with tensorflow
#    lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)
    layer= tf.contrib.rnn.BasicLSTMCell (rnn_width, activation=tf.tanh)    
    # Get lstm cell output
    
#    x_BN=BatchNormalization(x, w)
    
    
#    outputs, states = tf.contrib.rnn.static_rnn(layer, x_BN, dtype=tf.float32)

    return layer


#%%##############################################################################
# Building the encoder

def encoder(x, previous_state):
       
#       x = tf.reshape(x, [-1, input_dim])
       
       
       
       layer_full = tf.nn.tanh(tf.add(tf.matmul(x, weights['encoder_full'], biases['encoder_full'])))
#       layer_full = BatchNormalization(x, weights['encoder_full']);
       layer_full = tf.nn.tanh(layer_full);
       
       
       layer_full=BatchNormalization(layer_full, weights['encoder_rnn_1']);
       rnn_layer_1=rnn_layer_gen(rnn_width); #, weights['encoder_rnn_1'], biases['encoder_rnn_1'])
#       outputs_1, states_1 = tf.contrib.rnn.static_rnn(rnn_layer_1, layer_full, dtype=tf.float32)
#       outputs_1, states_1 = rnn_layer_1(layer_full, previous_state[:,0])
       
#       outputs_1=BatchNormalization(outputs_1, weights['encoder_rnn_2']);     
#       rnn_layer_2=rnn_layer_gen(rnn_width); #, weights['encoder_rnn_2'], biases['encoder_rnn_2'])
#       outputs_2, states_2 = tf.contrib.rnn.static_rnn(rnn_layer_2, outputs_1, dtype=tf.float32)
#       outputs_2, states_2 = rnn_layer_2(outputs_1, previous_state[:,1])
       
       rnn_net=tf.contrib.rnn.MultiRNNCell( [rnn_layer_1]*2, state_is_tuple=True)
#       initial_state=state = tf.zeros([batch_size, rnn_net.state_size])
       
       # Critical part where we get the state of rnn
       outputs, state_rnn = tf.contrib.rnn.static_rnn(rnn_net, layer_full, previous_state)

             
       #layer_middle=tf.nn.tanh(tf.add(tf.matmul(layer[str(n_hid)],weights['middle']), biases['middle']));
       layer_middle=BatchNormalization(outputs, weights['middle'])
       layer_middle=tf.nn.tanh(layer_middle)

       
       return layer_middle, state_rnn
#%% Building the decoder
def decoder(x, previous_state):
       
#       x=BatchNormalization(x, weights['decoder_rnn_1']);
       rnn_layer_1=rnn_layer_gen(rnn_width); #, weights['decoder_rnn_1'], biases['decoder_rnn_1'])
#       outputs_1, states_1 = tf.contrib.rnn.static_rnn(rnn_layer_1, x, dtype=tf.float32)
#       outputs_1, states_1 = rnn_layer_1(x, previous_state[:,0])
       
#       outputs_1=BatchNormalization(outputs_1, weights['encoder_rnn_2']);
#       rnn_layer_2=rnn_layer_gen(rnn_width); #, weights['decoder_rnn_2'], biases['decoder_rnn_2'])
#       outputs_2, states_2 = tf.contrib.rnn.static_rnn(rnn_layer_2, outputs_1, dtype=tf.float32)
#       outputs_2, states_2 = rnn_layer_2(outputs_1, previous_state[:,1])
       
       
       
       rnn_net=tf.contrib.rnn.MultiRNNCell( [rnn_layer_1]*2, state_is_tuple=True)
       
       
       # Critical part where we get the state of rnn
       outputs, state_rnn = tf.contrib.rnn.static_rnn(rnn_net, x, previous_state)


       layer_full=BatchNormalization(outputs, weights['decoder_full'])
       layer_full=tf.nn.tanh(layer_full) 
             
       
       layer_output=BatchNormalization(layer_full, weights['output'])
       layer_output=tf.nn.tanh(layer_output) 
    
       return layer_output, state_rnn
    

#%%#############################################################################
# Construct teh residual model

encoder_op={};
decoder_op={};
residue={};


# fisrt step

#previous_state_enc =tf.zeros([batch_size, hidden_width])
encoder_op, state_enc  = encoder(X, previous_state_enc)
decoder_op, state_dec = decoder(encoder_op,previous_state_dec) 

y_pred, _=decoder_op;
residue=tf.subtract(X, y_pred);

# Ground truth
y_true = X; # Targets (Labels) are the input data. Cause it's an Autoencoder!!

# Define loss and optimizer, minimize the squared error
cost = tf.reduce_mean( tf.pow(y_true - y_pred, 2))

#optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
#optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)
optimizer = tf.train.AdamOptimizer(learning_rate,  epsilon=1e-8).minimize(cost)


#%%##############################################################################
# Initializing the variables

init = tf.global_variables_initializer()

#with tf.Session() as sess:
sess=tf.Session();
#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))


sess.run(init)

# Training cycle
cost_vector=[];

for epoch in range(training_epochs):
    
       
       for  mini_batch in range(num_batches):
              
              start_ind=np.random.randint(0, n_training-batch_size*num_steps ,1) 
                               
              batch_xs= training_data[ start_ind : start_ind + batch_size*num_steps, :]    

#              batch_xs=tf.reshape(batch_xs, [batch_size, num_steps, input_dim])

                           
              state_enc_tmp = state_dec_tmp = tf.zeros([rnn_width, num_layers])
              
                           
              residue_tmp = tf.zeros([ batch_size, input_dim])
              
              
              for step_ind in range(num_steps):
                     
                     
#                     net_input=batch_xs[ step_ind * batch_size : (step_ind+1) * batch_size, : ]
                     net_input=batch_xs[ step_ind + np.arange(0, num_steps*batch_size, batch_size) , : ]
                     net_input=tf.subtract(net_input,residue_tmp);
                                          
                     residue_tmp, state_enc_tmp, state_dec_tmp=sess.run([residue, state_enc, state_dec],
                                                          feed_dict={X: net_input,                                                                    
                                                               previous_state_enc: state_enc_tmp,
                                                               previous_state_dec: state_dec_tmp })
                          
 
              c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs,\
                              previous_state_enc: state_enc_tmp,\
                              previous_state_dec: state_dec_tmp })
              
              # Display logs per epoch step
              if mini_batch % display_step == 0:
                     print("Epoch:", '%02d' % (epoch+1),
                           "i:", '%04d' % (mini_batch+1),
                           "cost=", "{:.9f}".format(c))   
            
              cost_vector+=[c]

print("Optimization Finished!")

#%%##########################################################################
# Testing the network performance

training_error=sess.run(cost, feed_dict={X: training_data})**0.5

y_pred_test, y_true_test, test_error = sess.run([y_pred, y_true, cost], feed_dict={X: test_data})

test_error=test_error**0.5

#_, test_error = sess.run([optimizer, cost], feed_dict={X: test_data})
print( 'training_error', "{:.9f}".format(training_error))
print( 'test_error', "{:.9f}".format(test_error))


#print('architecture ', [[hidden_width]*number_of_layers, n_hidden_binary, [hidden_width]*number_of_layers ])
print('learning_rate= ', learning_rate)
print('num_binary= ', num_binary)
#print('num_steps= ', num_steps)

# Plotting results
#plt.plot(cost_vector)

#%%##########################################################################
# Savings network
#saver = tf.train.Saver()
#save_path = saver.save(sess, "/home/hsadeghi/Dropbox/research codes/",
#                       "binary_full_2step_4bit_AE.ckpt")

#    print("Model saved in file: %s" % save_path)
AE_output={};
AE_output['y_pred_test']=y_pred_test;
AE_output['y_true_test']=y_true_test;

si.savemat("/home/hsadeghi/Dropbox/research codes/rnn_AE_output.mat",
           AE_output);


#%% Building graph

#writer = tf.summary.FileWriter('/Dropbox/research codes/log', sess.graph)









#
## Launch the graph
#with tf.Session() as sess:
#    sess.run(init)
#    step = 1
#    # Keep training until reach max iterations
#    while step * batch_size < training_iters:
#        batch_x, batch_y = mnist.train.next_batch(batch_size)
#        # Reshape data to get 28 seq of 28 elements
#        batch_x = batch_x.reshape((batch_size, n_steps, n_input))
#        # Run optimization op (backprop)
#        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})
#        if step % display_step == 0:
#            # Calculate batch accuracy
#            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})
#            # Calculate batch loss
#            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})
#            print("Iter " + str(step*batch_size) + ", Minibatch Loss= " + \
#                  "{:.6f}".format(loss) + ", Training Accuracy= " + \
#                  "{:.5f}".format(acc))
#        step += 1
#    print("Optimization Finished!")
#
#    # Calculate accuracy for 128 mnist test images
#    test_len = 128
#    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))
#    test_label = mnist.test.labels[:test_len]
#    print("Testing Accuracy:", \
#        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))